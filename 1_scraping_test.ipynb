{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d4945ac-5a9d-4cdd-9029-e84536190dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Libraries imported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49de11d9-5d9d-4c42-8a9c-f589189c054d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# The URL of the product page you want to scrape.\n",
    "# I'll use an example. Replace this with a real Amazon/Flipkart product URL.\n",
    "URL = \"https://www.amazon.in/Daikin-Inverter-Copper-Filter-MTKL35UV16/dp/B0BK28T4BZ/ref=sr_1_1_sspa?_encoding=UTF8&content-id=amzn1.sym.58c90a12-100b-4a2f-8e15-7c06f1abe2be&dib=eyJ2IjoiMSJ9.LpujZ4uISPUK8sa_6yNGVTLp2_seTR9samDUOPD7O27De5gR4wiXFNOAqexYtHRw8BdOCXbWsVVka54tE7wmzp0520p0LoTi57Xz1ZJK4iJqZyvF_DFiZoxTbLXluGeZbwBd-bRA70uiMd1aiZA1bMScj_EYRNMaRxI9X7U8eIXmYDJcuMWS9TZXf7LF06t5w8TV8MjG9Gx61gCSsen4zLmn6Uqtjjh9DpJ_MtQyX5vWyMjR35BjFcnb1laMqpqL8ij8onewzvqpv708KrDnLsA3KTUKs64RehFc1aQKJJE.NYIux8ldIlgBzvvXbUae9OYOeLvxAqeS-ydyKdC5mlc&dib_tag=se&pd_rd_r=d18d4de4-e171-46b6-b9f7-81df7001286f&pd_rd_w=atRXp&pd_rd_wg=m4RXC&qid=1761529367&refinements=p_85%3A10440599031&rps=1&s=kitchen&sr=1-1-spons&sp_csd=d2lkZ2V0TmFtZT1zcF9hdGZfYnJvd3Nl&th=1\" \n",
    "\n",
    "# CRITICAL: This header makes your request look like it's from a real browser.\n",
    "# Without it, Amazon will block you.\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Now, let's try to \"get\" the webpage\n",
    "webpage = requests.get(URL, headers=HEADERS)\n",
    "\n",
    "# Print the status code. 200 means success!\n",
    "# 503 or 403 means you were blocked.\n",
    "print(webpage.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47b0bc8e-642a-456a-b1f0-bc2ec5fdf7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daikin 1 Ton 3 Star Inverter Split AC (Copper, PM 2.5 Filter, 2024 Model, MTKL35UV16, White) : Amazon.in: Home & Kitchen\n"
     ]
    }
   ],
   "source": [
    "# Create the \"soup\" object\n",
    "# webpage.content is the raw HTML we downloaded\n",
    "soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "\n",
    "# Let's see the title of the page to make sure it worked\n",
    "print(soup.title.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe7157df-df7f-4177-9b83-0ec99f91618d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 247 reviews on this page.\n"
     ]
    }
   ],
   "source": [
    "# In Cell 4\n",
    "reviews = soup.find_all('div', {'class': 'a-row'})\n",
    "\n",
    "# --- OR whatever your class was ---\n",
    "# reviews = soup.find_all('div', {'class': 'review-container'}) \n",
    "\n",
    "# Now check the count again\n",
    "print(f\"Found {len(reviews)} reviews on this page.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "073bbd20-a6b6-4f2d-a162-809106802d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 247 ratings.\n",
      "Scraped 247 review texts.\n"
     ]
    }
   ],
   "source": [
    "# Create empty lists to hold our data\n",
    "all_ratings = []\n",
    "all_reviews = []\n",
    "\n",
    "# Loop through each review container\n",
    "for review in reviews:\n",
    "    \n",
    "    # 1. Get the rating\n",
    "    # We use a \"try...except\" block because sometimes a review is missing a rating\n",
    "    try:\n",
    "        # Find the star rating element\n",
    "        rating_element = review.find('i', {'data-hook': 'review-star-rating'})\n",
    "        # Get the text from its \"span\" child\n",
    "        rating_text = rating_element.find('span', {'class': 'a-icon-alt'}).get_text(strip=True)\n",
    "        # The text is \"4.0 out of 5 stars\", so we split it and take the first part\n",
    "        rating = float(rating_text.split(' ')[0])\n",
    "    except Exception as e:\n",
    "        rating = None # If it fails, just store \"None\"\n",
    "        \n",
    "    # 2. Get the review text\n",
    "    try:\n",
    "        # Find the review text element\n",
    "        review_text_element = review.find('span', {'data-hook': 'review-body'})\n",
    "        # Get the actual text\n",
    "        review_text = review_text_element.get_text(strip=True)\n",
    "    except Exception as e:\n",
    "        review_text = None # If it fails, store \"None\"\n",
    "        \n",
    "    # 3. Add our findings to our lists\n",
    "    all_ratings.append(rating)\n",
    "    all_reviews.append(review_text)\n",
    "\n",
    "# Let's check our work\n",
    "print(f\"Scraped {len(all_ratings)} ratings.\")\n",
    "print(f\"Scraped {len(all_reviews)} review texts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "910296f4-a384-4ebe-be8b-8a3ab5bc8462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     rating                                        review_text\n",
      "174     5.0  Very good ac, its new and its cooling is excel...\n",
      "178     5.0  Very good ac, its new and its cooling is excel...\n",
      "180     5.0  Very good ac, its new and its cooling is excel...\n",
      "189     1.0  Delivered on time and installation was done sa...\n",
      "197     4.0  Even though I purchased the product online the...\n",
      "\n",
      "Successfully saved data to reviews.csv!\n"
     ]
    }
   ],
   "source": [
    "# Create a pandas DataFrame (a table)\n",
    "df = pd.DataFrame({\n",
    "    'rating': all_ratings,\n",
    "    'review_text': all_reviews\n",
    "})\n",
    "\n",
    "# Clean up: Drop any rows where we failed to scrape either the rating or the text\n",
    "df = df.dropna()\n",
    "\n",
    "# Display the first 5 rows of our table\n",
    "print(df.head())\n",
    "\n",
    "# Save the table to a CSV file in your project folder\n",
    "df.to_csv('reviews.csv', index=False)\n",
    "\n",
    "print(\"\\nSuccessfully saved data to reviews.csv!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79431dc-62e5-4590-bc36-8dab81cf55c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
